const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights';

async function loadFaceApiModels() {
    if (state.faceApiModelsLoaded) return;

    domElements.analysisProgress.style.display = 'block';
    domElements.faceProgressText.textContent = 'ì–¼êµ´ ë¶„ì„ AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...';
    domElements.faceProgressFill.style.width = '0%';

    try {
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        domElements.faceProgressFill.style.width = '20%';
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        domElements.faceProgressFill.style.width = '40%';
        await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
        domElements.faceProgressFill.style.width = '60%';
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        domElements.faceProgressFill.style.width = '80%';
        await faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL);
        domElements.faceProgressFill.style.width = '100%';

        state.faceApiModelsLoaded = true;
        console.log('FaceAPI ëª¨ë¸ ë¡œë”© ì„±ê³µ');
        domElements.faceProgressText.textContent = 'AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
    } catch (error) {
        console.error('FaceAPI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:', error);
        domElements.faceProgressText.textContent = 'ì˜¤ë¥˜: AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
        domElements.analysisProgress.style.display = 'none';
        throw error;
    }
}

async function startFaceAnalysis() {
    if (state.faceAnalysisInProgress) {
        alert('ì´ë¯¸ ì–¼êµ´ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');
        return;
    }

    state.faceAnalysisInProgress = true;
    domElements.analyzeFacesBtn.disabled = true;
    domElements.analyzeFacesBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> ë¶„ì„ ì¤‘...';
    domElements.faceResults.innerHTML = '';

    try {
        await loadFaceApiModels();

        domElements.faceProgressText.textContent = 'ì˜ìƒì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...';
        const frames = await extractFrames(state.videoPlayer);

        const allDetections = await detectAllFaces(frames);

        domElements.faceProgressText.textContent = 'ë™ì¼ ì¸ë¬¼ì„ ê·¸ë£¹í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
        const actors = groupFaces(allDetections);

        domElements.faceProgressText.textContent = `ë¶„ì„ ì™„ë£Œ! ${actors.length}ëª…ì˜ ì¸ë¬¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.`;
        displayActors(actors);

    } catch (error) {
        console.error('ì–¼êµ´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
        domElements.faceProgressText.textContent = 'ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë¶„ì„ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.';
    } finally {
        state.faceAnalysisInProgress = false;
        domElements.analyzeFacesBtn.disabled = false;
        domElements.analyzeFacesBtn.innerHTML = 'ğŸ” ì–¼êµ´ ë¶„ì„ ì‹œì‘';
        setTimeout(() => { domElements.analysisProgress.style.display = 'none'; }, 2000);
    }
}

async function extractFrames(video, maxFrames = 20) {
    const frames = [];
    const duration = video.duration;
    if (duration <= 0) return [];
    
    const interval = duration / maxFrames;
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');

    const tempVideo = document.createElement('video');
    tempVideo.src = video.src;
    tempVideo.muted = true;
    await new Promise(res => tempVideo.onloadedmetadata = res);
    
    canvas.width = tempVideo.videoWidth;
    canvas.height = tempVideo.videoHeight;

    for (let i = 0; i < maxFrames; i++) {
        const time = i * interval;
        tempVideo.currentTime = time;
        await new Promise(res => setTimeout(() => tempVideo.onseeked = res, 50));
        
        ctx.drawImage(tempVideo, 0, 0, canvas.width, canvas.height);
        const imageDataUrl = canvas.toDataURL('image/jpeg', 0.7);
        frames.push({ time, imageDataUrl });

        domElements.faceProgressFill.style.width = `${(i + 1) / maxFrames * 25}%`;
    }
    return frames;
}

async function detectAllFaces(frames) {
    let allDetections = [];
    for (let i = 0; i < frames.length; i++) {
        const frame = frames[i];
        const img = await faceapi.fetchImage(frame.imageDataUrl);
        
        const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions({ scoreThreshold: 0.5 }))
            .withFaceLandmarks()
            .withFaceDescriptors()
            .withFaceExpressions()
            .withAgeAndGender();

        detections.forEach(d => {
            allDetections.push({ ...d, time: frame.time });
        });

        domElements.faceProgressText.textContent = `${i + 1}/${frames.length} í”„ë ˆì„ ë¶„ì„ ì¤‘...`;
        const progress = 25 + ((i + 1) / frames.length * 50);
        domElements.faceProgressFill.style.width = `${progress}%`;
    }
    return allDetections;
}

function groupFaces(detections, distanceThreshold = 0.5) {
    if (detections.length === 0) return [];
    
    const labeledDescriptors = detections.map((d, i) => new faceapi.LabeledFaceDescriptors(`person_${i}`, [d.descriptor]));
    const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, distanceThreshold);

    return detections.reduce((actors, det) => {
        const bestMatch = faceMatcher.findBestMatch(det.descriptor);
        const label = bestMatch.label;
        
        let actor = actors.find(a => a.id === label);
        if (!actor) {
            actor = { 
                id: label, 
                name: `ë°°ìš° ${actors.length + 1}`,
                detections: [] 
            };
            actors.push(actor);
        }
        actor.detections.push(det);
        return actors;
    }, []);
}

function displayActors(actors) {
    domElements.faceResults.innerHTML = '';
    actors.sort((a, b) => b.detections.length - a.detections.length);

    actors.forEach((actor, index) => {
        actor.name = `ë°°ìš° ${index + 1}`; // Re-assign name after sorting
        const bestShot = actor.detections.reduce((a, b) => a.detection.score > b.detection.score ? a : b);
        
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        const { x, y, width, height } = bestShot.detection.box;
        canvas.width = width;
        canvas.height = height;
        const img = new Image();
        img.onload = () => {
            ctx.drawImage(img, x, y, width, height, 0, 0, width, height);
        };
        img.src = bestShot.alignedRect.image.src; // This is a bit of a hack
        
        const card = document.createElement('div');
        card.className = 'face-card';

        const avgAge = Math.round(actor.detections.reduce((sum, d) => sum + d.age, 0) / actor.detections.length);
        const expressions = actor.detections.map(d => Object.keys(d.expressions).reduce((a, b) => d.expressions[a] > d.expressions[b] ? a : b));
        const mostCommonExpression = expressions.sort((a,b) => expressions.filter(v => v===a).length - expressions.filter(v => v===b).length).pop();

        const firstAppearance = new Date(actor.detections[0].time * 1000).toISOString().substr(14, 5);

        card.innerHTML = `
            <img src="${img.src}" alt="${actor.name}" style="width:100%; height: auto; border-radius: 8px;">
            <h4>${actor.name}</h4>
            <div class="face-info">
                <div>ë“±ì¥ íšŸìˆ˜: ${actor.detections.length}íšŒ</div>
                <div>ì¶”ì • ë‚˜ì´: ~${avgAge}ì„¸</div>
                <div>ì£¼ìš” í‘œì •: ${mostCommonExpression}</div>
                <div>ì²« ë“±ì¥: ${firstAppearance}</div>
            </div>
        `;
        domElements.faceResults.appendChild(card);
    });
} 